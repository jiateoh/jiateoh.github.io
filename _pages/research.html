---
permalink: /experience/
layout: single
classes: wide  
---
<h1>Research</h1>


<h2><a href="{{ site.url }}/pdfs/FlowDebug_SoCC2020_camera-ready.pdf">Influence-Based Provenance for Dataflow Applications with Taint Propagation</a></h2>
<p>
	Debugging big data analytics often requires a root cause analysis to pinpoint the precise culprit records in an input dataset responsible for incorrect or anomalous output. Existing debugging or data provenance approaches do not track fine-grained control and data flows in user-defined application code; thus, the returned culprit data is often too large for manual inspection and expensive post-mortem analysis is required.
<br/>
<br/>
	Given a suspicious set of target output records, FlowDebug is designed to identify a highly precise set of input records based on two key insights. First, it precisely tracks control and data flow within user-defined functions to propagate taints at a fine-grained level by inserting custom data abstractions through automated source to source transformation. Second, it introduces a novel notion of influence-based provenance for many-to-one dependencies to prioritize which input records are more responsible than others by analyzing the semantics of a user-defined function used for aggregation. By design, our approach does not require any modification to the frameworkâ€™s runtime and can be applied to existing applications easily. FlowDebug significantly improves the precision of debugging results by up to 99.9 percentage points and avoids repetitive re-runs required for post-mortem analysis by a factor of 33 while incurring an instrumentation overhead of 0.4X - 6.1X on vanilla Spark. 
<br/>
<br/>
	FlowDebug is published in the ACM Symposium on Cloud Computing 2020, which had a 24.4% acceptance rate. <a href="{{ site.url }}/pdfs/FlowDebug_SoCC2020_camera-ready.pdf">paper</a> <a href="{{ site.url }}/pdfs/flowdebug-poster.pdf">poster</a>
</p>
<h2><a href="{{ site.url }}/pdfs/socc2019-perfdebug-teoh.pdf">PerfDebug: Performance Debugging of Computational Skew in Data-Intensive Scalable Computing</a></h2>
<p>
	PerfDebug is a fine-grained performance provenance system that combines latency instrumentation with data provenance to investigate what we define as computational skew: skew in performance related not only to data skew (distribution), but also the computational latencies associated with individual records through program definition (e.g., user-defined functions). Although the current implementation uses Apache Spark, the underlying ideas and heuristics can be transferred to most other distributed cluster-computing frameworks. The project aims to provide application developers with the ability to answer computational skew queries such as <i>"What are the latencies and input records associated with individual output records?"</i> and <i>"Which input records have the largest impact on job performance and why?"</i>.
	<br/>
	<br/>
	PerfDebug is published in the ACM Symposium on Cloud Computing 2019, which had a 24.8% acceptance rate. <a href="{{ site.url }}/pdfs/socc2019-perfdebug-teoh.pdf">paper</a> <a href="{{ site.url }}/pdfs/SoCC_2019-PerfDebug_Poster.pdf">poster</a>
</p>
<h2>Nanoflow: Mobile Dataflow</h2>
<p>
	Previously, I worked in the <a href="https://scai.cs.ucla.edu/">Scalable Analytics Institute (ScAi)</a> under <a href="http://clash.cs.ucla.edu/"> Professor Tyson Condie</a>. There, I partnered with <a href="http://web.cs.ucla.edu/~jnoor/">Joseph Noor</a> to develop Nanoflow, a mobile dataflow processing framework integrated with cloud computing systems. In particular, we implemented a stream processing framework for Android devices that integrates with Apache Spark clusters. Using our system, application developers can submit a Spark job that operates on data originating from mobile data sources. Traditionally, such jobs require that all mobile data is pushed to the cluster, which then runs all required computations. Nanoflow instead integrates with Spark so that some computation (e.g., filters) can be automatically executed directly on the mobile device prior to data delivery to the computing cluster (Spark). By automatically splitting the execution graph and running some computation directly on mobile devices, our approach can improve job latency, throughput, and scalability while also tailoring jobs to account for mobile-specific requirements such as energy usage and network bandwidth limits.
	<img src="/assets/images/nanoflow_overview.png" alt="Nanoflow overview" style="background-color:white">
	<!-- ![Nanoflow overview](/assets/images/nanoflow_overview.png) -->
</p>

<h2>Industry Experience</h2>
<p>
	Before joining the PhD program at UCLA, I worked at LinkedIn Corporation for three years in the Data Analytics Infrastructure organization (formerly Data Services). I spent two of those years on the LISTT+NCRM team developing an audience segmentation tool and computation pipeline that enabled marketing campaigns to accurately target desirable users based on a wide variety of attributes defined by our marketing operations team (<a href="https://www.slideshare.net/r39132/linkedins-segmentation-targeting-platform">2013 slides</a>). I spent one year working on <a href="https://github.com/apache/incubator-pinot/tree/master/thirdeye"> Thirdeye</a> to develop a workflow for realtime monitoring/anomaly detection and root-cause analysis.



