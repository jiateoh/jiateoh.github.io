---
permalink: /research/
layout: single
classes: wide  
---
<h1>Research</h1>
<h2>PerfDebug: Performance Debugging of Computational Skew in Data-Intensive Scalable Computing</h2>
<p>
	My current research project is a fine-grained performance provenance system that combines latency instrumentation with data provenance to investigate what we define as computational skew: skew in performance related not only to data skew (distribution), but also the computational latencies associated with individual records through program definition (e.g., user-defined functions). Although the current implementation uses Apache Spark, the underlying ideas and heuristics can be transferred to most other distributed cluster-computing frameworks. The project aims to provide application developers with the ability to answer computational skew queries such as <i>"What are the latencies and input records associated with individual output records?"</i> and <i>"Which input records have the largest impact on job performance and why?"</i>.
</p>
<h2>Nanoflow: Mobile Dataflow</h2>
<p>
	Previously, I worked in the <a href="https://scai.cs.ucla.edu/">Scalable Analytics Institute (ScAi)</a> under <a href="http://clash.cs.ucla.edu/"> Professor Tyson Condie</a>. There, I partnered with <a href="http://web.cs.ucla.edu/~jnoor/">Joseph Noor</a> to develop Nanoflow, a mobile dataflow processing framework integrated with cloud computing systems. In particular, we implemented a stream processing framework for Android devices that integrates with Apache Spark clusters. Using our system, application developers can submit a Spark job that operates on data originating from mobile data sources. Traditionally, such jobs require that all mobile data is pushed to the cluster, which then runs all required computations. Nanoflow instead integrates with Spark so that some computation (e.g., filters) can be automatically executed directly on the mobile device prior to data delivery to the computing cluster (Spark). By automatically splitting the execution graph and running some computation directly on mobile devices, our approach can improve job latency, throughput, and scalability while also tailoring jobs to account for mobile-specific requirements such as energy usage and network bandwidth limits.
	<img src="/assets/images/nanoflow_overview.png" alt="Nanoflow overview" style="background-color:white">
	<!-- ![Nanoflow overview](/assets/images/nanoflow_overview.png) -->
</p>



